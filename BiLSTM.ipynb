{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b085c3fc",
   "metadata": {},
   "source": [
    "## Coursework Task 1: Extracting Entities from Scientific Abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e397d5",
   "metadata": {},
   "source": [
    "In Natural Language Processing, Named Entity Recognition is a process of extracting the important information from large unstructered text data and classifying those entities into suitable categories. In this project, we will look at the task of extracting entity types such as Task, Process and Material from corpus of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97af97a",
   "metadata": {},
   "source": [
    "**WARNING:** If you are interested in running this notebook, please install keras 1.14.0 and tensorflow 2.3.1. There are some dependency issues with the latest tensorflow library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf57f8f",
   "metadata": {},
   "source": [
    "**Reference** : https://towardsdatascience.com/named-entity-recognition-ner-meeting-industrys-requirement-by-applying-state-of-the-art-deep-698d2b3b4ede"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f9bb3",
   "metadata": {},
   "source": [
    "## Method 2: BiLSTM with ELMo embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af875522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scienceie_loader import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Input\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12c3a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The versions of tensorflow and keras are 1.14.0 and 2.3.1.\n"
     ]
    }
   ],
   "source": [
    "#version of tensorflow and keras\n",
    "print(f\"The versions of tensorflow and keras are {tf.__version__} and {keras.__version__}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b0ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow.compat.v1 as tf\n",
    "#To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8cc1f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for dataset\n",
    "data_root = os.path.join(os.getcwd(), 'original_datasets')\n",
    "data_train = os.path.join(data_root, 'scienceie2017_train/train2')\n",
    "data_dev = os.path.join(data_root, 'scienceie2017_dev/dev')\n",
    "data_test = os.path.join(data_root, 'semeval_articles_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and assigning NER tags\n",
    "train_docs, train_rels, _ = load_tokenized_data(data_train)\n",
    "dev_docs, dev_rels, _ = load_tokenized_data(data_dev)\n",
    "test_docs, test_rels, _ = load_tokenized_data(data_test)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd43fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting document into sentences\n",
    "\n",
    "def doc_to_sentence(docs):\n",
    "    result = []\n",
    "    temp = []\n",
    "    atemp = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        for word, tag in doc:\n",
    "            if word != \".\":\n",
    "                atemp.append((word, tag))\n",
    "            else:\n",
    "                atemp.append(('.', 'O'))\n",
    "                temp.append(atemp)\n",
    "                atemp = list()\n",
    "                \n",
    "        result.append(temp)\n",
    "        temp = list()\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8aa70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(itertools.chain.from_iterable(doc_to_sentence(train_docs)))\n",
    "dev = list(itertools.chain.from_iterable(doc_to_sentence(dev_docs)))\n",
    "test = list(itertools.chain.from_iterable(doc_to_sentence(test_docs)))\n",
    "data = train+test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a38751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'B-Task': 1086,\n",
       "         'I-Task': 4266,\n",
       "         'O': 43767,\n",
       "         'B-Process': 2727,\n",
       "         'I-Process': 5666,\n",
       "         'B-Material': 2251,\n",
       "         'I-Material': 2558})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagss = [tag for sent in train for sent, tag in sent]\n",
    "tagss_count = Counter(tagss)\n",
    "tagss_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b7a058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(sen) for sen in train], bins= 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fed49",
   "metadata": {},
   "source": [
    "The histogram tells us that most of the sentences with the length in the range between 20 to 200. So, we will consider 150 as maximum length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128c5e1",
   "metadata": {},
   "source": [
    "### Vocabulary is made of all the words in train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cbf8d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12241\n"
     ]
    }
   ],
   "source": [
    "#vocabulary\n",
    "words = list({word for sentence in data for word, tag in sentence})\n",
    "words_length = len(words)\n",
    "print(words_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4efa537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "#Possible ner tags\n",
    "tags = list({tag for doc in train_docs for word, tag in doc})\n",
    "tags_length = len(tags)\n",
    "print(tags_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c95a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximum length of a sentence to consider\n",
    "max_len = 150\n",
    "tags2index = {t:i for i,t in enumerate(tags)}\n",
    "idx2tag = {i: w for w, i in tags2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07969ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'B-Task': 1086,\n",
       "         'I-Task': 4266,\n",
       "         'O': 43767,\n",
       "         'B-Process': 2727,\n",
       "         'I-Process': 5666,\n",
       "         'B-Material': 2251,\n",
       "         'I-Material': 2558})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagss_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69d106de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(lst):\n",
    "    \"\"\"function that assign the term 'Padding' if the sentence is less than max_len\"\"\"\n",
    "    result = []\n",
    "    for sentence in lst:\n",
    "        temp = []\n",
    "        for i in range(max_len):\n",
    "            try:\n",
    "                temp.append(sentence[i][0])\n",
    "            except:\n",
    "                temp.append(\"Padding\")\n",
    "        result.append(temp)\n",
    "        \n",
    "    return result\n",
    "X_tr = padding(train)\n",
    "X_dev = padding(dev)\n",
    "X_te = padding(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7efa2042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(lst):\n",
    "    \"\"\"function that create a sequence of padding (converting tags to index)\"\"\"\n",
    "    result = []\n",
    "    for sentence in lst:\n",
    "        temp = []\n",
    "        for tup in sentence:\n",
    "            temp.append(tags2index[tup[1]])\n",
    "            \n",
    "        result.append(temp)\n",
    "        \n",
    "    return result\n",
    "  \n",
    "y_tr = pad_sequences(maxlen = max_len, sequences = pad_seq(train), padding = \"post\", value = tags2index[\"O\"])\n",
    "y_te = pad_sequences(maxlen = max_len, sequences = pad_seq(test), padding = \"post\", value = tags2index[\"O\"])\n",
    "y_dev = pad_sequences(maxlen = max_len, sequences = pad_seq(dev), padding = \"post\", value = tags2index[\"O\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef200d14",
   "metadata": {},
   "source": [
    "It takes sometime to install elmo embedding if you are installing for the first time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92c3bb",
   "metadata": {},
   "source": [
    "Initialize the ELMo embedding from tensorflow hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b906ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True) #ELMO embedding files\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abdfd225",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(inputs={\"tokens\": tf.squeeze(tf.cast(x,tf.string)),\"sequence_len\": tf.constant(batch_size*[max_len])\n",
    "                     },\n",
    "                      signature=\"tokens\",\n",
    "                      as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9aca37",
   "metadata": {},
   "source": [
    "1024 dimensional vectors of the ELMo embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = Input(shape=(max_len,), dtype=tf.string)\n",
    "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
    "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
    "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "\n",
    "x = add([x, x_rnn])\n",
    "output = TimeDistributed(Dense(tags_length, activation=\"softmax\"))(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e26bce3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\deepta\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "E:\\Anaconda\\envs\\deepta\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n",
      "E:\\Anaconda\\envs\\deepta\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:538: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_text, output)\n",
    "model.compile(optimizer=\"adam\", loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d5001",
   "metadata": {},
   "source": [
    "The number of samples divisible by the batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2961e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tr[:22*batch_size]\n",
    "X_val = X_dev[:3*batch_size]\n",
    "y_train = y_tr[:22*batch_size]\n",
    "y_val = y_dev[:3*batch_size]\n",
    "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
    "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0019eeee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(np.array(X_train), y_train, validation_data=(np.array(X_val), y_val),batch_size=batch_size, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac8fc99e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 50s 222ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test = X_te[:7*batch_size]\n",
    "test_pred = model.predict(np.array(X_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12957ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2label(pred):\n",
    "    \"\"\"function to convert tags2idx to label in predicted list\"\"\"\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PADword\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "\n",
    "def test2label(pred):\n",
    "     \"\"\"function to convert tags2idx to label in test list\"\"\"\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            out_i.append(idx2tag[p].replace(\"PADword\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = test2label(y_te[:7*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1137569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted and true labels\n",
    "pred = list(itertools.chain.from_iterable(pred_labels))\n",
    "true = list(itertools.chain.from_iterable(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f696002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words list length\n",
    "n_words = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b896f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [tag for word, tag in list(idx2tag.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80ea7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   B-Process       0.42      0.22      0.29       670\n",
      "   I-Process       0.33      0.07      0.11       712\n",
      "  B-Material       0.00      0.00      0.00       131\n",
      "      I-Task       0.47      0.18      0.26       650\n",
      "      B-Task       0.38      0.11      0.17      1012\n",
      "           O       0.25      0.13      0.17       550\n",
      "  I-Material       0.91      0.99      0.95     29875\n",
      "\n",
      "    accuracy                           0.89     33600\n",
      "   macro avg       0.39      0.24      0.28     33600\n",
      "weighted avg       0.85      0.89      0.86     33600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\deepta\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\envs\\deepta\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\envs\\deepta\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true, pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85ab6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BPT(lst):\n",
    "    \n",
    "    \"\"\"function that converts B and I tags of a given entity to single\n",
    "    NER tag\"\"\"\n",
    "    \n",
    "    #example: \"B-Process\" and \"I-Process\" to \"Process\"\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    for element in lst:\n",
    "        if element == \"O\":\n",
    "            result.append(\"O\")\n",
    "        elif element == \"B-Material\" or element == \"I-Material\":\n",
    "            result.append(\"Material\")\n",
    "        elif element == \"B-Process\" or element == \"I-Process\":\n",
    "            result.append(\"Process\")\n",
    "        elif element == \"B-Task\" or element == \"I-Task\":\n",
    "            result.append(\"Task\")\n",
    "            \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f9fd3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Material       0.54      0.25      0.34      1320\n",
      "           O       0.91      0.99      0.95     29875\n",
      "     Process       0.42      0.11      0.17      1724\n",
      "        Task       0.27      0.11      0.16       681\n",
      "\n",
      "    accuracy                           0.89     33600\n",
      "   macro avg       0.53      0.36      0.40     33600\n",
      "weighted avg       0.86      0.89      0.87     33600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(BPT(true), BPT(pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f58e91c",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb08242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the values of entity, true and pred\n",
    "dictionary = {\n",
    "             \"true tag\":[],\n",
    "             \"predicted tag\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19666d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary[\"entity\"] = [word for word, tag in test[82][:11]]\n",
    "dictionary[\"true tag\"] = test_labels[82][:11]\n",
    "dictionary[\"predicted tag\"] = pred_labels[82][:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "784f0afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>true tag</th>\n",
       "      <th>predicted tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apache</td>\n",
       "      <td>B-Process</td>\n",
       "      <td>B-Process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pig</td>\n",
       "      <td>I-Process</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>platform</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>creating</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MapReduce</td>\n",
       "      <td>B-Process</td>\n",
       "      <td>I-Task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>workflows</td>\n",
       "      <td>I-Process</td>\n",
       "      <td>I-Task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>with</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hadoop.</td>\n",
       "      <td>B-Material</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       entity    true tag predicted tag\n",
       "0      Apache   B-Process     B-Process\n",
       "1         Pig   I-Process             O\n",
       "2          is           O             O\n",
       "3           a           O             O\n",
       "4    platform           O             O\n",
       "5         for           O             O\n",
       "6    creating           O             O\n",
       "7   MapReduce   B-Process        I-Task\n",
       "8   workflows   I-Process        I-Task\n",
       "9        with           O             O\n",
       "10    Hadoop.  B-Material             O"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe\n",
    "df = pd.DataFrame(data = dictionary)\n",
    "df = df[[\"entity\", \"true tag\", \"predicted tag\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72892d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2269f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ee719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
