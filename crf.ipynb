{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coursework Task 1: Extracting Entities from Scientific Abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Natural Language Processing, Named Entity Recognition is a process of extracting the important information from large unstructered text data and classifying those entities into suitable categories. In this project, we will look at the task of extracting entity types such as Task, Process and Material from corpus of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Conditional random fields + POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from pathlib import Path\n",
    "from scienceie_loader import *\n",
    "\n",
    "from sklearn_crfsuite import CRF, metrics\n",
    "from sklearn.metrics import make_scorer, f1_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tag import CRFTagger\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, we will divide a document into sentences and assign POS tags to each word in the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset path\n",
    "data_root = os.path.join(os.getcwd(), 'original_datasets')\n",
    "data_train = os.path.join(data_root, 'scienceie2017_train/train2')\n",
    "data_dev = os.path.join(data_root, 'scienceie2017_dev/dev')\n",
    "data_test = os.path.join(data_root, 'semeval_articles_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training documents: 350\n",
      "number of dev documents: 50\n",
      "number of test documents: 100\n"
     ]
    }
   ],
   "source": [
    "#tokenized data\n",
    "train_docs, train_rels, _ = load_tokenized_data(data_train)\n",
    "dev_docs, dev_rels, _ = load_tokenized_data(data_dev)\n",
    "test_docs, test_rels, _ = load_tokenized_data(data_test)\n",
    "\n",
    "print(f'number of training documents: {len(train_docs)}')\n",
    "print(f'number of dev documents: {len(dev_docs)}')\n",
    "print(f'number of test documents: {len(test_docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels\n",
    "labels = sorted(list({tag for doc in train_docs for word, tag in doc}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have decided to split the document into sentences. So, it would give us a more datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_sentence(docs):\n",
    "    \"\"\"function that split document into sentences\"\"\"\n",
    "    answer = []\n",
    "    result = []\n",
    "    a = []\n",
    "    for doc in docs:\n",
    "        for word, ner in doc:\n",
    "            if word !=\".\":\n",
    "                a.append((word, ner))\n",
    "            else:\n",
    "                a.append(('.', 'O'))\n",
    "                result.append(a)\n",
    "                a = list()\n",
    "        answer.append(result)\n",
    "        result = list()\n",
    "        \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(lst):\n",
    "    \"\"\"function that assign pos tag to each word in a sentence\"\"\"\n",
    "    answer = []\n",
    "    temp = []\n",
    "    \n",
    "    for doc in lst:\n",
    "        for sentence in doc:\n",
    "            words = [word for word, ner in sentence]\n",
    "            pos_tags = nltk.pos_tag(words)\n",
    "            atemp = []\n",
    "            \n",
    "            for num in range(len(pos_tags)):\n",
    "                atemp.append((sentence[num][0], pos_tags[num][1], sentence[num][1]))\n",
    "            temp.append(atemp)\n",
    "            atemp = list()\n",
    "        answer.append(temp)\n",
    "        temp = list()\n",
    "        \n",
    "    return answer\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set and test_set are in the form [[[sentence1, sentence2, ...]]]\n",
    "train_set = pos(docs_sentence(train_docs))\n",
    "test_set = pos(docs_sentence(test_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test\n",
    "train = [sentence for document in train_set for sentence in document]\n",
    "test = [sentence for document in test_set for sentence in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lengths of train and test are 717 and 248 respectively.\n"
     ]
    }
   ],
   "source": [
    "#lengths of train and test\n",
    "print(f\"The lengths of train and test are {len(train)} and {len(test)} respectively.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create features needed to perform named entity recognition. In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used.\n",
    "\n",
    "This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it.\n",
    "\n",
    "sklearn-crfsuite (and python-crfsuite) supports several feature formats; here we use feature dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRFfeatures(sentence, counter):\n",
    "    \n",
    "    \"\"\"function to create features for NER\"\"\"\n",
    "    \n",
    "    word = sentence[counter][0]\n",
    "    pos_tag = sentence[counter][1]\n",
    "    \n",
    "    \"\"\"dictionary to save all the values of the features\"\"\"\n",
    "    result = { \"POS_Tag[:2]\" : pos_tag[:2],\n",
    "               \"POS_Tag\" : pos_tag,\n",
    "               \"word.isdigit()\" : word.isdigit(),\n",
    "               \"word.istitle()\" : word.istitle(),\n",
    "               \"word.isupper()\" : word.isupper(),\n",
    "               \"word[-2:]\" : word[-2:],\n",
    "               \"word[-3:]\" : word[-3:],\n",
    "               \"word.lower()\" : word.lower(),\n",
    "               \"bias\" : 1.0\n",
    "    }\n",
    "    \n",
    "    if counter > 1:\n",
    "        previousword = sentence[counter-1][0]\n",
    "        previouspos_tag = sentence[counter-1][1]\n",
    "        \n",
    "        result.update({ \"previous:word.lower()\": previousword.lower(),\n",
    "                          \"previous:word.istitle()\": previousword.istitle(),\n",
    "                          \"previous:word.isupper()\": previousword.isupper(),\n",
    "                          \"previous:POS_Tag\": previouspos_tag,\n",
    "                          \"previous:POS_Tag[:2]\": previouspos_tag[:2]\n",
    "                        })\n",
    "    else:\n",
    "        result[\"BOS\"] = True\n",
    "    \n",
    "    if counter < len(sentence)-1:\n",
    "        nextword = sentence[counter+1][0]\n",
    "        nextpos_tag = sentence[counter+1][1]\n",
    "   \n",
    "        result.update({ \"next:word.lower()\": nextword.lower(),\n",
    "                          \"next:word.istitle()\": nextword.istitle(),\n",
    "                          \"next:word.isupper()\": nextword.isupper(),\n",
    "                          \"next:POS_Tag\": nextpos_tag,\n",
    "                          \"next:POS_Tag[:2]\": nextpos_tag[:2]\n",
    "                        })  \n",
    "    else:\n",
    "        result[\"EOS\"] = True\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(sentence):\n",
    "    \n",
    "    \"\"\"function that returns the features for each word in a sentence\"\"\"\n",
    "    return [CRFfeatures(sentence, number) for number in range(len(sentence))]\n",
    "\n",
    "def assign_labels(sentence):\n",
    "    \n",
    "    \"\"\"function that returns the NER tag for each word in a sentence\"\"\"\n",
    "    return [label for token, pos, label in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = [extract_features(sentence) for sentence in train]\n",
    "y_train = [assign_labels(sentence) for sentence in train]\n",
    "X_test = [extract_features(sentence) for sentence in test]\n",
    "y_test = [assign_labels(sentence) for sentence in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm=\"lbfgs\",\n",
    "          c1=0.30017377233926223,\n",
    "          c2=0.11259458226548057,\n",
    "          max_iterations=1000,\n",
    "          all_possible_transitions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c1 and c2 values are obtained using RandomizedSearchCV technique. Sometime, I get CRF keep_tempfiles error and only way I could solve this issue by restarting the notebook. Thats why I have removed my hyperparamter tuning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-Material       0.38      0.22      0.28       810\n",
      "   B-Process       0.41      0.27      0.32       883\n",
      "      B-Task       0.15      0.12      0.14       187\n",
      "  I-Material       0.34      0.32      0.33       759\n",
      "   I-Process       0.26      0.32      0.29      1248\n",
      "      I-Task       0.16      0.22      0.18       737\n",
      "           O       0.87      0.88      0.87     16473\n",
      "\n",
      "    accuracy                           0.74     21097\n",
      "   macro avg       0.37      0.34      0.34     21097\n",
      "weighted avg       0.74      0.74      0.74     21097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BPT(lst):\n",
    "    \n",
    "    \"\"\"function that converts B and I tags of a given entity to single\n",
    "    NER tag\"\"\"\n",
    "    \n",
    "    #example: \"B-Process\" and \"I-Process\" to \"Process\"\n",
    "\n",
    "    a = list(itertools.chain.from_iterable(lst))\n",
    "    result = []\n",
    "    \n",
    "    for element in a:\n",
    "        if element == \"O\":\n",
    "            result.append(\"O\")\n",
    "        elif element == \"B-Material\" or element == \"I-Material\":\n",
    "            result.append(\"Material\")\n",
    "        elif element == \"B-Process\" or element == \"I-Process\":\n",
    "            result.append(\"Process\")\n",
    "        elif element == \"B-Task\" or element == \"I-Task\":\n",
    "            result.append(\"Task\")\n",
    "            \n",
    "    return result      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Material       0.41      0.31      0.35      1569\n",
      "           O       0.87      0.88      0.87     16473\n",
      "     Process       0.35      0.34      0.35      2131\n",
      "        Task       0.17      0.21      0.19       924\n",
      "\n",
      "    accuracy                           0.75     21097\n",
      "   macro avg       0.45      0.44      0.44     21097\n",
      "weighted avg       0.75      0.75      0.75     21097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(BPT(y_test), BPT(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the values of entity, true and pred\n",
    "dictionary = {\n",
    "             \"true tag\":[],\n",
    "             \"predicted tag\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary[\"entity\"] = [word for word, pos, ne_tag in test[82][:11]]\n",
    "dictionary[\"true tag\"] = y_test[82][:11]\n",
    "dictionary[\"predicted tag\"] = y_pred[82][:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>true tag</th>\n",
       "      <th>predicted tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apache</td>\n",
       "      <td>B-Process</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pig</td>\n",
       "      <td>I-Process</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>platform</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>creating</td>\n",
       "      <td>O</td>\n",
       "      <td>B-Task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MapReduce</td>\n",
       "      <td>B-Process</td>\n",
       "      <td>I-Task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>workflows</td>\n",
       "      <td>I-Process</td>\n",
       "      <td>I-Task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>with</td>\n",
       "      <td>O</td>\n",
       "      <td>I-Task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hadoop.</td>\n",
       "      <td>B-Material</td>\n",
       "      <td>I-Task</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       entity    true tag predicted tag\n",
       "0      Apache   B-Process             O\n",
       "1         Pig   I-Process             O\n",
       "2          is           O             O\n",
       "3           a           O             O\n",
       "4    platform           O             O\n",
       "5         for           O             O\n",
       "6    creating           O        B-Task\n",
       "7   MapReduce   B-Process        I-Task\n",
       "8   workflows   I-Process        I-Task\n",
       "9        with           O        I-Task\n",
       "10    Hadoop.  B-Material        I-Task"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe\n",
    "df = pd.DataFrame(data = dictionary)\n",
    "df = df[[\"entity\", \"true tag\", \"predicted tag\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
